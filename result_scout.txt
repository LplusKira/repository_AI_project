   # logs
   # todo: remember some structures(or rules) to win 
   # fix: our opponent need to be simple agent(based on cardnum or cardvalue) instead random agent
   # fix: every player have different evaluation value...
   # idea: all max search for each player's evaluation
           # not every player want to kill me...
   # todo: check gameend when search
   # because cardnum is very important, raise the weight of cardnum


   report: 相生相克的情形很多
   todo: 1card, 2card seperate

   
   '''
   3 vs 1
   CardNumberHeuristicAgent wins: 1569 games
   AllMaxHeuristicAgent wins: 431 games
   CardNumberHeuristicAgent wins: 1660 games
   ScoutAgent wins: 340 games
   CardNumberHeuristicAgent wins: 1623 games
   HeuristicAgent wins: 377 games

   mypower = [0, 10, 10, 10, 60, 80, -60, 50, -80, 100, 70, 80, 80, 70]
   myendpower = [0, -30, -30, -20, 60, 80, -40, 50, -55, -200, 80, 80, 100, 80]
   mydeadvalue = -200
   mycardvalue = 200
   myninevalue = -120
     362 30.6%

   mypower = [0, 10, 10, 10, 60, 80, -60, 50, -80, 100, 70, 80, 80, 70]
   myendpower = [0, -30, -30, -20, 60, 80, -40, 50, -55, -200, 80, 80, 100, 80]
   mydeadvalue = -300
   mycardvalue = 200
   myninevalue = -180
       without diff: 32.3%(646/2000)
       if diff <= -6 or mycardlen <= 2: 31.4%(156/500)
       if diff <= -3 :                    bad
       if diff <= -3 and mycardlen <= 3: 33.8%(380/1124)
         only count realplayer's cardvalue: 36.8%(184/500)
	 only count knowncards' cardvalue: 34.2%(183/535)
	 count knowncard with higher value, unknown card with lower(1/mountain length): 35.4%(354/1000)
	 count realplayer with higher value, unknown card with lower(1/mountain length): 37.5%(518/1381)
	 count knowncard or realplayer with higher value, unknown card with lower(1/mountain length): bad, about 30%
	 add heursitic in mycardlen = 1:  31.2% (312/1000)
	     if  mycardlen == 1: now testing
                for card in self.card[myid]:
                    v = getCardValue(card)
                    if v == 9: # check is drawn or not... need to label known cards
                        score = 5000
                    elif ((v <= 3 and card != 1) or v == 6 or v == 8) and self.point + v > 99:
                        score = mydeadvalue
                    else:
                        score += myendpower[v]

	[:] is shallow copy...
   use random gen cards to test bestmove is correct or not
   add known cards to dpevalall
   
   test result:
   heuristic        depth result(2000times) techniques
   cardnum            1   38.5%(6/18)
   power              2   ?%              power = [0, 20, 10, 10, 60, 80, -30, 10, -50, 80, 80, 60, 100, 80]
   dynamic-power      2   ?% (56% vs heuristic) self.dpeval(), when card < 2, preserve 9 as killer.
   dynamic-power      2   36.6% (% vs heuristic) self.dpeval1(), when card < 2, preserve 9 as killer.
   dynamic-power      1   37.7% (% vs heuristic) self.dpeval1(), when card < 2, preserve 9 as killer.
   dynamic-power      1   38% (% vs heuristic) self.dpeval1(), remember cards
   dynamic-power      1   39.85% (% vs heuristic) self.dpeval1(), remember cards, no trim getaction in simjudge
   dynamic-power      1   37.75% (% vs heuristic) self.dpeval1(), remember cards, no trim getaction in simjudge, improve fillstate...
   '''
